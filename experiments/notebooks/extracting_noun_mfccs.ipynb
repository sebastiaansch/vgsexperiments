{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helper import tokenize, dicttodf, returnnouns, create_noun_set\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Flickr8k_text/Flickr8k.token.txt\"\n",
    "wordlist, worddictionary = tokenize(\"data/Flickr8k_text/Flickr8k.token.txt\")\n",
    "worddf = dicttodf(worddictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take the POS tags of the words in the flickr8k set\n",
    "postags = nltk.pos_tag(worddf[\"words\"][0:254])\n",
    "\n",
    "#take out only the nouns\n",
    "nouns = returnnouns(postags)\n",
    "nouns = pd.DataFrame(nouns)\n",
    "nouns = nouns.iloc[:,0]\n",
    "len(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanscholten/opt/anaconda3/envs/paperreproduction/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"H5F.c\", line 509, in H5Fopen\n    unable to open file\n  File \"H5Fint.c\", line 1400, in H5F__open\n    unable to open file\n  File \"H5Fint.c\", line 1615, in H5F_open\n    unable to lock the file\n  File \"H5FD.c\", line 1640, in H5FD_lock\n    driver lock request failed\n  File \"H5FDsec2.c\", line 941, in H5FD_sec2_lock\n    unable to lock file, errno = 35, error message = 'Resource temporarily unavailable'\n\nEnd of HDF5 error back trace\n\nUnable to open/create file '/Users/sebastiaanscholten/Documents/speech2image-master/experiments/Generating_Flickrwords_mfcc/mfcc/words_mfcc_features.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-709fdb30b607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#make new set with only mfcc features of chosen nouns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mh5_with_mfccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/sebastiaanscholten/Documents/speech2image-master/experiments/Generating_Flickrwords_mfcc/mfcc/words_mfcc_features.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_with_mfccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmfccset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_noun_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnouns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/paperreproduction/lib/python3.7/site-packages/tables/file.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/paperreproduction/lib/python3.7/site-packages/tables/file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"H5F.c\", line 509, in H5Fopen\n    unable to open file\n  File \"H5Fint.c\", line 1400, in H5F__open\n    unable to open file\n  File \"H5Fint.c\", line 1615, in H5F_open\n    unable to lock the file\n  File \"H5FD.c\", line 1640, in H5FD_lock\n    driver lock request failed\n  File \"H5FDsec2.c\", line 941, in H5FD_sec2_lock\n    unable to lock file, errno = 35, error message = 'Resource temporarily unavailable'\n\nEnd of HDF5 error back trace\n\nUnable to open/create file '/Users/sebastiaanscholten/Documents/speech2image-master/experiments/Generating_Flickrwords_mfcc/mfcc/words_mfcc_features.h5'"
     ]
    }
   ],
   "source": [
    "nouns.to_csv(\"data/testwords.txt\", index=False)\n",
    "\n",
    "\n",
    "#make new set with only mfcc features of chosen nouns\n",
    "h5_with_mfccs = \"/Users/sebastiaanscholten/Documents/speech2image-master/experiments/Generating_Flickrwords_mfcc/mfcc/words_mfcc_features.h5\"\n",
    "data_file = tables.open_file(h5_with_mfccs, mode='r+')\n",
    "mfccset = create_noun_set(list(nouns),data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mfccset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-72df8d5a6cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmfccset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mfccset' is not defined"
     ]
    }
   ],
   "source": [
    "mfccset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_txt = pd.read_csv(\"/Users/sebastiaanscholten/Documents/speech2image-master/experiments/data/testwords.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['dog'],\n",
       "       ['man'],\n",
       "       ['boy'],\n",
       "       ['woman'],\n",
       "       ['girl'],\n",
       "       ['water'],\n",
       "       ['grass'],\n",
       "       ['person'],\n",
       "       ['jumping'],\n",
       "       ['field'],\n",
       "       ['group'],\n",
       "       ['air'],\n",
       "       ['beach'],\n",
       "       ['mouth'],\n",
       "       ['street'],\n",
       "       ['bike'],\n",
       "       ['rock'],\n",
       "       ['play'],\n",
       "       ['orange'],\n",
       "       ['player'],\n",
       "       ['pool'],\n",
       "       ['hat'],\n",
       "       ['jacket'],\n",
       "       ['background'],\n",
       "       ['dirt'],\n",
       "       ['toy'],\n",
       "       ['soccer'],\n",
       "       ['wall'],\n",
       "       ['mountain'],\n",
       "       ['park'],\n",
       "       ['face'],\n",
       "       ['football'],\n",
       "       ['sand'],\n",
       "       ['stick'],\n",
       "       ['car'],\n",
       "       ['tennis'],\n",
       "       ['tree'],\n",
       "       ['snowy'],\n",
       "       ['baby'],\n",
       "       ['picture'],\n",
       "       ['bicycle'],\n",
       "       ['hair'],\n",
       "       ['jump'],\n",
       "       ['road'],\n",
       "       ['area'],\n",
       "       ['basketball'],\n",
       "       ['race'],\n",
       "       ['head'],\n",
       "       ['bench'],\n",
       "       ['game'],\n",
       "       ['catch'],\n",
       "       ['sit'],\n",
       "       ['ground'],\n",
       "       ['hand'],\n",
       "       ['dress'],\n",
       "       ['something'],\n",
       "       ['fence'],\n",
       "       ['path'],\n",
       "       ['ramp'],\n",
       "       ['city'],\n",
       "       ['wave'],\n",
       "       ['side'],\n",
       "       ['baseball'],\n",
       "       ['track'],\n",
       "       ['boat'],\n",
       "       ['coat'],\n",
       "       ['motorcycle'],\n",
       "       ['rope'],\n",
       "       ['suit'],\n",
       "       ['couple'],\n",
       "       ['watch'],\n",
       "       ['snowboarder'],\n",
       "       ['river'],\n",
       "       ['horse'],\n",
       "       ['ice'],\n",
       "       ['pose'],\n",
       "       ['midair'],\n",
       "       ['playground'],\n",
       "       ['blonde'],\n",
       "       ['collar']], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_txt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
